---
phase: 01-aws-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/aws/user-data.sh
  - scripts/aws/provision.sh
autonomous: true
requirements:
  - INFRA-01
  - INFRA-02
  - INFRA-03
  - INFRA-04
  - INFRA-05

must_haves:
  truths:
    - "EC2 instance is running in us-east-1 with state 'running'"
    - "SSH key pair PEM file exists locally with 400 permissions"
    - "Security group has exactly two ingress rules: port 80 from 0.0.0.0/0 and port 22 from admin IP"
    - "Instance was launched with gp3 30 GB root volume"
    - "user-data script installs Docker Engine and Docker Compose v2 plugin on AL2023"
  artifacts:
    - path: "scripts/aws/user-data.sh"
      provides: "cloud-init script that installs Docker + Compose on AL2023"
      contains: "dnf install -y docker"
    - path: "scripts/aws/provision.sh"
      provides: "AWS CLI provisioning script that creates key pair, SG, and launches instance"
      contains: "aws ec2 run-instances"
  key_links:
    - from: "scripts/aws/provision.sh"
      to: "scripts/aws/user-data.sh"
      via: "--user-data file://user-data.sh reference in run-instances"
      pattern: "user-data.*user-data\\.sh"
    - from: "scripts/aws/provision.sh"
      to: "AWS EC2 API"
      via: "create-key-pair → create-security-group → authorize-ingress → run-instances → wait"
      pattern: "aws ec2 run-instances"
---

<objective>
Provision a t3.small EC2 instance on AWS with Docker Engine and Docker Compose v2 installed via user-data, behind a security group that exposes only port 80 (public) and port 22 (admin IP).

Purpose: Create the infrastructure substrate that Phase 2 and 3 will deploy the Matrix/Element stack onto. Nothing can run without a reachable, Docker-ready EC2 instance.

Output: Two executable scripts (`scripts/aws/user-data.sh` and `scripts/aws/provision.sh`), a running EC2 instance, and a local SSH key file.
</objective>

<execution_context>
@/Users/myownip/.config/claude/get-shit-done/workflows/execute-plan.md
@/Users/myownip/.config/claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-aws-infrastructure/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create user-data.sh cloud-init script for Docker on AL2023</name>
  <files>scripts/aws/user-data.sh</files>
  <action>
Create `scripts/aws/user-data.sh` — a bash cloud-init script that runs on first boot of the AL2023 EC2 instance. Use the AL2023 built-in docker package approach (NOT Docker CE via CentOS repo — avoids the $releasever workaround).

The script MUST:

1. Start with `#!/bin/bash` and `set -euo pipefail` (silent user-data failures are the #1 cause of "Docker not found" on EC2)
2. `dnf update -y` — system update
3. `dnf install -y docker` — installs Docker Engine, CLI, containerd from AL2023 built-in repo
4. Create `/etc/docker/daemon.json` with:
   - `"exec-opts": ["native.cgroupdriver=systemd"]`
   - `"log-driver": "json-file"` with `"max-size": "100m"` and `"max-file": "3"` (prevents log disk exhaustion)
5. `systemctl enable --now docker` — start Docker and enable on boot
6. `usermod -aG docker ec2-user` — allow ec2-user to run docker without sudo
7. Install Docker Compose v2 as a system-wide CLI plugin:
   - `mkdir -p /usr/local/lib/docker/cli-plugins`
   - `curl -sSL "https://github.com/docker/compose/releases/latest/download/docker-compose-linux-$(uname -m)" -o /usr/local/lib/docker/cli-plugins/docker-compose`
   - `chmod +x /usr/local/lib/docker/cli-plugins/docker-compose`

Make the file executable (`chmod +x`).

Do NOT include any Docker CE repo addition, do NOT use `amazon-linux-extras` (AL2 only), do NOT install `docker-compose` standalone v1 binary.
  </action>
  <verify>
Run `cat scripts/aws/user-data.sh` and confirm:
- Starts with `#!/bin/bash` and `set -euo pipefail`
- Contains `dnf install -y docker` (NOT docker-ce)
- Contains daemon.json creation with log rotation config
- Contains `systemctl enable --now docker`
- Contains `usermod -aG docker ec2-user`
- Contains Docker Compose binary install to `/usr/local/lib/docker/cli-plugins/docker-compose`
- File is executable: `ls -la scripts/aws/user-data.sh` shows `x` bits
  </verify>
  <done>user-data.sh exists, is executable, and contains the complete AL2023 Docker + Compose v2 installation sequence</done>
</task>

<task type="auto">
  <name>Task 2: Create provision.sh and execute it to launch EC2 instance</name>
  <files>scripts/aws/provision.sh</files>
  <action>
Create `scripts/aws/provision.sh` — an AWS CLI script that provisions the full EC2 infrastructure. Then execute it.

The script MUST implement this exact sequence:

**Variables at top:**
```bash
REGION="us-east-1"
KEY_NAME="matrix-poc-key"
SG_NAME="matrix-poc-sg"
INSTANCE_NAME="matrix-poc"
```

**Pre-flight check:**
- Verify default VPC exists: `aws ec2 describe-vpcs --region "$REGION" --filters Name=isDefault,Values=true --query "Vpcs[0].VpcId" --output text` — abort if result is "None" or empty
- Detect admin IP: `ADMIN_IP="$(curl -s https://checkip.amazonaws.com)/32"`
- Print admin IP for the user to see

**Step 1 — INFRA-05: Create SSH key pair**
```bash
aws ec2 create-key-pair \
  --region "$REGION" \
  --key-name "$KEY_NAME" \
  --key-type rsa \
  --key-format pem \
  --query "KeyMaterial" \
  --output text > "${KEY_NAME}.pem"
chmod 400 "${KEY_NAME}.pem"
```
Save the PEM file in the current working directory (the script should `cd` to its own directory first with `SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"` and `cd "$SCRIPT_DIR"`).

**Step 2 — INFRA-02: Create security group + ingress rules**
```bash
SG_ID=$(aws ec2 create-security-group \
  --region "$REGION" \
  --group-name "$SG_NAME" \
  --description "Matrix POC: port 80 public, port 22 admin only" \
  --query "GroupId" \
  --output text)

# Port 80: public access for HTTP (Nginx/Element)
aws ec2 authorize-security-group-ingress \
  --region "$REGION" \
  --group-id "$SG_ID" \
  --protocol tcp --port 80 --cidr 0.0.0.0/0

# Port 22: admin SSH only
aws ec2 authorize-security-group-ingress \
  --region "$REGION" \
  --group-id "$SG_ID" \
  --protocol tcp --port 22 --cidr "$ADMIN_IP"
```
Do NOT add port 8008 — Synapse is Docker-internal only.

**Step 3 — INFRA-01, INFRA-03, INFRA-04: Launch instance**
```bash
INSTANCE_ID=$(aws ec2 run-instances \
  --region "$REGION" \
  --image-id "resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64" \
  --instance-type t3.small \
  --count 1 \
  --key-name "$KEY_NAME" \
  --security-group-ids "$SG_ID" \
  --block-device-mappings '[{"DeviceName":"/dev/xvda","Ebs":{"VolumeSize":30,"VolumeType":"gp3","DeleteOnTermination":true}}]' \
  --user-data file://user-data.sh \
  --tag-specifications \
    "ResourceType=instance,Tags=[{Key=Name,Value=${INSTANCE_NAME}}]" \
    "ResourceType=volume,Tags=[{Key=Name,Value=${INSTANCE_NAME}-root}]" \
  --query "Instances[0].InstanceId" \
  --output text)
```
Note: `--user-data file://user-data.sh` uses a relative path — the script must `cd` to its own directory first so the file reference resolves.

**Step 4 — Wait and extract public DNS**
```bash
aws ec2 wait instance-running --region "$REGION" --instance-ids "$INSTANCE_ID"

PUBLIC_DNS=$(aws ec2 describe-instances \
  --region "$REGION" \
  --instance-ids "$INSTANCE_ID" \
  --query "Reservations[0].Instances[0].PublicDnsName" \
  --output text)
```

**Step 5 — Output summary**
Print:
- Instance ID
- Public DNS hostname
- SSH command: `ssh -i ${KEY_NAME}.pem ec2-user@${PUBLIC_DNS}`
- Reminder: "Wait 2-3 minutes for cloud-init to finish before SSHing in"

**Step 6 — Save instance metadata to a file**
Write `instance-info.env` in the script directory with:
```
INSTANCE_ID=<value>
PUBLIC_DNS=<value>
SG_ID=<value>
KEY_FILE=<path to pem>
ADMIN_IP=<value>
REGION=<value>
```
This file will be consumed by Plan 02 for verification.

Make the script executable. Then execute it:
```bash
cd scripts/aws && bash provision.sh
```

If `create-key-pair` fails because the key already exists, the script should print an error message and exit (do NOT silently continue with a stale key). Similarly, if the security group already exists, print a clear error.

Add `set -euo pipefail` at the top so any AWS CLI failure aborts immediately.
  </action>
  <verify>
After execution, verify:
1. `scripts/aws/provision.sh` exists and is executable
2. `scripts/aws/matrix-poc-key.pem` exists with `400` permissions
3. `scripts/aws/instance-info.env` exists and contains INSTANCE_ID, PUBLIC_DNS, SG_ID
4. Run: `source scripts/aws/instance-info.env && aws ec2 describe-instances --region "$REGION" --instance-ids "$INSTANCE_ID" --query "Reservations[0].Instances[0].State.Name" --output text` — should return "running"
5. Run: `aws ec2 describe-security-groups --region "$REGION" --group-ids "$SG_ID" --query "SecurityGroups[0].IpPermissions" --output json` — should show exactly 2 rules (port 80 and port 22)
  </verify>
  <done>EC2 instance is running, SSH key exists locally, security group has correct rules, instance-info.env captures all metadata needed for verification</done>
</task>

</tasks>

<verification>
1. `aws ec2 describe-instances --instance-ids $INSTANCE_ID` shows State=running, InstanceType=t3.small
2. Security group has exactly 2 ingress rules: TCP/80 from 0.0.0.0/0 and TCP/22 from admin IP
3. Block device mapping shows 30 GB gp3 volume
4. Key PEM file exists with 400 permissions
5. instance-info.env contains all required metadata fields
</verification>

<success_criteria>
- EC2 instance is in "running" state in us-east-1
- SSH key pair PEM file exists locally at scripts/aws/matrix-poc-key.pem with 400 permissions
- Security group allows only port 80 (0.0.0.0/0) and port 22 (admin IP) — no port 8008
- Instance was launched with t3.small, gp3 30 GB volume, and user-data.sh
- instance-info.env written with instance metadata for Plan 02 to consume
</success_criteria>

<output>
After completion, create `.planning/phases/01-aws-infrastructure/01-01-SUMMARY.md`
</output>
